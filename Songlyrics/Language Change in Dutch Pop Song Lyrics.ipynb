{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "TOKENIZER = nltk.tokenize.word_tokenize\n",
    "def is_punct(t):\n",
    "    return re.match(f'[{string.punctuation}]+$', t) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Change in Dutch Pop Song Lyrics (1989 - 2018)\n",
    "\n",
    "_Alie Lassche_\n",
    "\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Is today's popular music worse than it was several years ago? In an [article](https://slate.com/technology/2014/08/musical-nostalgia-the-psychology-and-neuroscience-for-song-preference-and-the-reminiscence-bump.html) on Slate, Mark Jospeh Stern asks himself why the songs he heard when he was a teenager sound sweeter than anything he listens to as an adult. To answer this question he investigates the brain's relationship with music and states that our reaction to music depends on how we interact with it. The more we like a song, the more we get treated to neurochemical bliss. Since our brains undergo rapid neurological development between the ages of 12 and 22, the music we love during that decade seems to get wired in our lobes for good. Combine that with the fact that songs from our youth form the soundtrack to what feels, at that time, like the most vital and momentous years of lives, and you'll have the conclusion as Stern puts it: you'll never love another song the way you loved the music of your youth.\n",
    "\n",
    "Carl Sharpe asks himself almost the same question in an [article](https://towardsdatascience.com/49-years-of-lyrics-why-so-angry-1adf0a3fa2b4) on Towards Data Science: \"I _know_ late 90s music was the best music of all time (see Neural Nostalgia article above), but how could I prove/disprove that? How could I measure something so subjective?\" In his article\n",
    "he presents the results of a Python based study of the change in language for popular music from 1970 to 2018. One of the hypotheses he tests is that lyrics have become more aggressive and profane over the past 49 years. The dataset contains popular songs that were in the Billboard Top 100 between 1978 and 2018. In other studies on the language of song lyrics (take a look [here](https://www.johnwmillr.com/trucks-and-beer/), [here](https://towardsdatascience.com/does-country-music-drink-more-than-other-genres-a21db901940b) and [here](https://github.com/Hugo-Nattagh/2017-Hip-Hop)), the corpus consists of English popsongs as well. Drawing inspiration from the quantitative analytic studies on song lyrics mentioned above, I will research the change in language in lyrics of Dutch popular songs.\n",
    "\n",
    "The research question I will answer in this study is: how do the dominant sentiments in Dutch song lyrics change between 1989 and 2018? To answer this question I use the Linguistic Inquiry and Word Count ([LIWC](http://liwc.wpengine.com)), which is a software program to analyse text by counting words in 66 psychologically meaningful categories that are calculated in a dictionary of words. The LIWC reads a given text and counts the percentages of words that fall in a certain category. Since it was originally developed by researchers with interest in social, clinical, health and cognitive psychology, the language categories were created to capture people's social and psychological states. The LIWC is an English dictionary, but is translated in many languages, among which the Dutch language. In this study I use the Dutch translation of the LIWC 2007 version.\n",
    "\n",
    "In what follows I will first examine the making of the dataset I used, after which I will discuss the Dutch LIWC in detail. Subsequently there will be paragraphs on the analysis and the results. I will end with a conclusion and a discussion.\n",
    "\n",
    "\n",
    "## 2. Corpus\n",
    "\n",
    "To create a dataset, I used a method similar to Stern's. Instead of using the Top 100 of Billboard, I went to the Dutch equivalent: the [Top40](https://www.top40.nl). Here the 'Top 100-Jaaroverzicht' can be found from 1965 until 2018. I checked each list (as from 1989 until 2018) manually for artists that wrote songs in Dutch. I created a list with the names of these artists, dividing the thirty years in three decades, resulting in a dataframe with three columns, each containing the names of artists that were in the Top 100 during the following decades: 1989 - 1998, 1999 - 2008, 2009 - 2018.\n",
    "\n",
    "After that I wrote a script that, given an artist from the above mentioned dataframe, scrapes corresponding song titles from [Genius](www.genius.com). The name of the artist and the song titles were saved in a dictionary - one for each decade. The next step was to clean this dictionary.\n",
    "\n",
    "- remove English songs\n",
    "- remove wrong artists\n",
    "\n",
    "Maar, dit kan ook na het scrapen van de lyrics. Misschien zelfs makkelijker.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analysis\n",
    "\n",
    "## 4. Results\n",
    "\n",
    "## 5. Conclusion\n",
    "\n",
    "## 6. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZORGEN DAT DE INDEX-KOLOM DE NAAM VAN DE ARTIEST BEVAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import os\n",
    "from codecs import open\n",
    "\n",
    "#------------ DUTCH DATA --------------\n",
    "\n",
    "csv = '/Users/alielassche/documents/github/cultural-analytics/LIWC_Dutch.csv'\t\t#load Dutch LIWC data\n",
    "\n",
    "csvfile = open(csv,\"r\", encoding='utf-8')\n",
    "liwcfile = csvfile.read().split(\"\\n\")\n",
    "csvfile.close()\n",
    "\n",
    "liwc_nl_dict = dict()\n",
    "for line in liwcfile:\n",
    "\tline = line.rsplit(\",\")\n",
    "\tliwc_nl_dict[line[0]] = line[1:]\n",
    "\n",
    "\n",
    "#----------- FUNCTIONS ----------------\n",
    "\n",
    "\n",
    "def freqdict(text):\n",
    "\n",
    "\t\"\"\"This function returns a frequency dictionary of the input list. All words are transformed to lower case.\"\"\"\n",
    "\t\n",
    "\tfreq_dict = dict() \n",
    "\tfor word in text:\n",
    "\t\tword = word.lower()\n",
    "\t\tif word in freq_dict:\n",
    "\t\t\tfreq_dict[word] += 1\n",
    "\t\telse:\n",
    "\t\t\tfreq_dict[word] = 1\n",
    "\treturn freq_dict\n",
    "\n",
    "def liwc(text,output='rel',lang='nl'):\n",
    "\n",
    "\t\"\"\"This function takes a list of tokens as input and returns a dictionary with the relative (output='rel') or absolute (output='abs') frequencies for every LIWC category. This function works for languages English (lang='en') and Dutch (lang='nl').\"\"\"\n",
    "\n",
    "\t#decide on relative or absolute frequenc\n",
    "\tif output == 'abs': #absolute frequency as output\n",
    "\t\tdivision = 1\n",
    "\telif output == 'rel': #relative frequency as output\n",
    "\t\tdivision = len(text)\n",
    "\n",
    "\t#make frequency dictionary of the text to diminish number of runs in further for loop\n",
    "\tfreq_dict = freqdict(text) \t\n",
    "\t\n",
    "\tif lang == 'nl':\n",
    "\t\tliwc_dict = liwc_nl_dict\n",
    "\telse:\n",
    "\t\tliwc_dict = liwc_en_dict\n",
    "\t\n",
    "\tfeatures = dict()\t\t\n",
    "\tfor category in liwc_dict:\n",
    "\t\tfreq = 0\n",
    "\t\tfor term in liwc_dict[category]:\n",
    "\t\t\tterm = term.lower()\n",
    "\t\t\tif term[-1] == u\"*\": #'*' indicates partial words that should match the beginning of the word (include variations on words)\n",
    "\t\t\t\tfor word in freq_dict:\n",
    "\t\t\t\t\tif word.startswith(term[:-1]):\n",
    "\t\t\t\t\t\tfreq += freq_dict[word]\n",
    "\t\t\telse:\n",
    "\t\t\t\tif term in freq_dict:\n",
    "\t\t\t\t\tfreq += freq_dict[term]\n",
    "\t\tfeatures[category] = freq / division\n",
    "\t\t\n",
    "\treturn features\n",
    "\n",
    "def liwc_nl(text,output=\"rel\"):\n",
    "\t\"\"\"This function applies Dutch liwc() on input. Output is relative frequencies of liwc categories.\"\"\"\n",
    "\treturn liwc(text,output=output,lang=\"nl\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tdoc = '/Users/alielassche/documents/github/cultural-analytics/decade1/Lyrics_WillekeAlberti.txt'\n",
    "\t\n",
    "\t\n",
    "# \twith open(doc, 'r') as myfile:\n",
    "# \t\tdata = myfile.read().replace('\\n', ' ')\n",
    "# \t\tdata = data.split(\" \")\n",
    "# \t\tliwc(data,output='rel',lang='nl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(doc, 'r') as myfile:\n",
    "    chars = myfile.read().replace('\\n', ' ')\n",
    "    words = []\n",
    "    for sentence in TOKENIZER(chars, language=\"dutch\"):\n",
    "        words.extend([w.lower() for w in sentence.split() if not is_punct(w)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Andre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Othref</th>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>0.090278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inhib</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Space</th>\n",
       "      <td>0.017677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Posemo</th>\n",
       "      <td>0.027146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self</th>\n",
       "      <td>0.075126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Social</th>\n",
       "      <td>0.080808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humans</th>\n",
       "      <td>0.001263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sports</th>\n",
       "      <td>0.000631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.003788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swear</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discrep</th>\n",
       "      <td>0.018939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nonfl</th>\n",
       "      <td>0.000631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You</th>\n",
       "      <td>0.025253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cause</th>\n",
       "      <td>0.010101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sexual</th>\n",
       "      <td>0.003788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Achieve</th>\n",
       "      <td>0.000631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relig</th>\n",
       "      <td>0.000631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cogmech</th>\n",
       "      <td>0.054924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>We</th>\n",
       "      <td>0.006313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Senses</th>\n",
       "      <td>0.026515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eating</th>\n",
       "      <td>0.000631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Optim</th>\n",
       "      <td>0.000631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incl</th>\n",
       "      <td>0.056187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leisure</th>\n",
       "      <td>0.003788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job</th>\n",
       "      <td>0.001894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hear</th>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Preps</th>\n",
       "      <td>0.082702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Affect</th>\n",
       "      <td>0.051136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>0.068813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Groom</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tentat</th>\n",
       "      <td>0.014520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Up</th>\n",
       "      <td>0.006313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion</th>\n",
       "      <td>0.029040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negate</th>\n",
       "      <td>0.017677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Future</th>\n",
       "      <td>0.010732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Death</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Article</th>\n",
       "      <td>0.036616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fillers</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family</th>\n",
       "      <td>0.005051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pronoun</th>\n",
       "      <td>0.126894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metaph</th>\n",
       "      <td>0.000631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feel</th>\n",
       "      <td>0.007576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Certain</th>\n",
       "      <td>0.022096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insight</th>\n",
       "      <td>0.016414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assent</th>\n",
       "      <td>0.004419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number</th>\n",
       "      <td>0.008838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sad</th>\n",
       "      <td>0.011995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Past</th>\n",
       "      <td>0.058712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Down</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>See</th>\n",
       "      <td>0.007576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TV</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sleep</th>\n",
       "      <td>0.000631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Money</th>\n",
       "      <td>0.003157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anger</th>\n",
       "      <td>0.001263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Posfeel</th>\n",
       "      <td>0.013258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anx</th>\n",
       "      <td>0.001894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negemo</th>\n",
       "      <td>0.020833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Occup</th>\n",
       "      <td>0.004419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Andre\n",
       "Othref   0.041667\n",
       "Time     0.090278\n",
       "Inhib    0.000000\n",
       "Space    0.017677\n",
       "Posemo   0.027146\n",
       "Self     0.075126\n",
       "Social   0.080808\n",
       "Humans   0.001263\n",
       "Sports   0.000631\n",
       "Other    0.003788\n",
       "Music    0.000000\n",
       "Swear    0.000000\n",
       "Discrep  0.018939\n",
       "Nonfl    0.000631\n",
       "You      0.025253\n",
       "Cause    0.010101\n",
       "Sexual   0.003788\n",
       "Achieve  0.000631\n",
       "Relig    0.000631\n",
       "Cogmech  0.054924\n",
       "We       0.006313\n",
       "Senses   0.026515\n",
       "Eating   0.000631\n",
       "Optim    0.000631\n",
       "Incl     0.056187\n",
       "Leisure  0.003788\n",
       "Job      0.001894\n",
       "Hear     0.011364\n",
       "Preps    0.082702\n",
       "Affect   0.051136\n",
       "...           ...\n",
       "I        0.068813\n",
       "Groom    0.000000\n",
       "Tentat   0.014520\n",
       "Up       0.006313\n",
       "Motion   0.029040\n",
       "Negate   0.017677\n",
       "Future   0.010732\n",
       "Death    0.000000\n",
       "Article  0.036616\n",
       "Fillers  0.000000\n",
       "Family   0.005051\n",
       "Pronoun  0.126894\n",
       "Metaph   0.000631\n",
       "Feel     0.007576\n",
       "Certain  0.022096\n",
       "Insight  0.016414\n",
       "Assent   0.004419\n",
       "Number   0.008838\n",
       "Sad      0.011995\n",
       "Past     0.058712\n",
       "Down     0.000000\n",
       "See      0.007576\n",
       "TV       0.000000\n",
       "Sleep    0.000631\n",
       "Money    0.003157\n",
       "Anger    0.001263\n",
       "Posfeel  0.013258\n",
       "Anx      0.001894\n",
       "Negemo   0.020833\n",
       "Occup    0.004419\n",
       "\n",
       "[68 rows x 1 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(liwc(words,output='rel', lang='nl'), orient='index', columns=['Andre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Achieve</th>\n",
       "      <th>Affect</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Anx</th>\n",
       "      <th>Article</th>\n",
       "      <th>Assent</th>\n",
       "      <th>Body</th>\n",
       "      <th>Cause</th>\n",
       "      <th>Certain</th>\n",
       "      <th>Cogmech</th>\n",
       "      <th>...</th>\n",
       "      <th>Social</th>\n",
       "      <th>Space</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Swear</th>\n",
       "      <th>TV</th>\n",
       "      <th>Tentat</th>\n",
       "      <th>Time</th>\n",
       "      <th>Up</th>\n",
       "      <th>We</th>\n",
       "      <th>You</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>De Sjonnies</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033939</td>\n",
       "      <td>0.003152</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>0.061576</td>\n",
       "      <td>0.013576</td>\n",
       "      <td>0.013091</td>\n",
       "      <td>0.005818</td>\n",
       "      <td>0.020848</td>\n",
       "      <td>0.044121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069818</td>\n",
       "      <td>0.016970</td>\n",
       "      <td>0.007030</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>0.033697</td>\n",
       "      <td>0.016242</td>\n",
       "      <td>0.003152</td>\n",
       "      <td>0.019152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hakkûhbar</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032243</td>\n",
       "      <td>0.013751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028924</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>0.007587</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>0.014699</td>\n",
       "      <td>0.028924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048364</td>\n",
       "      <td>0.042200</td>\n",
       "      <td>0.009957</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014699</td>\n",
       "      <td>0.044097</td>\n",
       "      <td>0.013276</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.013751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DJ Madman</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012841</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.024077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004815</td>\n",
       "      <td>0.065811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165329</td>\n",
       "      <td>0.004815</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038523</td>\n",
       "      <td>0.083467</td>\n",
       "      <td>0.006421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ome Henk</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024903</td>\n",
       "      <td>0.003874</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.054234</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.007748</td>\n",
       "      <td>0.043165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037631</td>\n",
       "      <td>0.022136</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.012175</td>\n",
       "      <td>0.024350</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.008854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mannenkoor karrespoor</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>0.009950</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>0.009950</td>\n",
       "      <td>0.034826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039801</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049751</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Achieve    Affect     Anger       Anx   Article  \\\n",
       "De Sjonnies                0.0  0.033939  0.003152  0.001697  0.061576   \n",
       "Hakkûhbar                  0.0  0.032243  0.013751  0.000000  0.028924   \n",
       "DJ Madman                  0.0  0.086677  0.000000  0.012841  0.022472   \n",
       "Ome Henk                   0.0  0.024903  0.003874  0.000553  0.054234   \n",
       "Mannenkoor karrespoor      0.0  0.049751  0.000000  0.000000  0.074627   \n",
       "\n",
       "                         Assent      Body     Cause   Certain   Cogmech  \\\n",
       "De Sjonnies            0.013576  0.013091  0.005818  0.020848  0.044121   \n",
       "Hakkûhbar              0.004742  0.007587  0.002371  0.014699  0.028924   \n",
       "DJ Madman              0.001605  0.024077  0.000000  0.004815  0.065811   \n",
       "Ome Henk               0.002214  0.016602  0.007194  0.007748  0.043165   \n",
       "Mannenkoor karrespoor  0.004975  0.009950  0.004975  0.009950  0.034826   \n",
       "\n",
       "                         ...       Social     Space    Sports     Swear  \\\n",
       "De Sjonnies              ...     0.069818  0.016970  0.007030  0.000485   \n",
       "Hakkûhbar                ...     0.048364  0.042200  0.009957  0.001897   \n",
       "DJ Madman                ...     0.165329  0.004815  0.001605  0.000000   \n",
       "Ome Henk                 ...     0.037631  0.022136  0.000553  0.000000   \n",
       "Mannenkoor karrespoor    ...     0.039801  0.004975  0.000000  0.000000   \n",
       "\n",
       "                             TV    Tentat      Time        Up        We  \\\n",
       "De Sjonnies            0.000000  0.012121  0.033697  0.016242  0.003152   \n",
       "Hakkûhbar              0.000000  0.014699  0.044097  0.013276  0.000948   \n",
       "DJ Madman              0.000000  0.038523  0.083467  0.006421  0.000000   \n",
       "Ome Henk               0.000553  0.012175  0.024350  0.010515  0.001107   \n",
       "Mannenkoor karrespoor  0.000000  0.000000  0.049751  0.014925  0.019900   \n",
       "\n",
       "                            You  \n",
       "De Sjonnies            0.019152  \n",
       "Hakkûhbar              0.013751  \n",
       "DJ Madman              0.110754  \n",
       "Ome Henk               0.008854  \n",
       "Mannenkoor karrespoor  0.000000  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('decade1_liwc_names.csv', sep=';', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fillers    0.003894\n",
      "TV         0.006488\n",
      "Nonfl      0.006778\n",
      "Swear      0.016422\n",
      "Groom      0.017999\n",
      "School     0.024512\n",
      "Down       0.025390\n",
      "Inhib      0.025856\n",
      "Death      0.032974\n",
      "Job        0.052025\n",
      "Friends    0.057547\n",
      "Anx        0.065253\n",
      "Achieve    0.074014\n",
      "Sports     0.075452\n",
      "Relig      0.078856\n",
      "Home       0.091372\n",
      "Assent     0.101676\n",
      "Anger      0.102907\n",
      "Music      0.103822\n",
      "Sleep      0.106605\n",
      "Optim      0.108378\n",
      "We         0.108784\n",
      "Metaph     0.111785\n",
      "Eating     0.124774\n",
      "Family     0.126232\n",
      "Money      0.127853\n",
      "Occup      0.151109\n",
      "Cause      0.155353\n",
      "Sexual     0.169150\n",
      "Humans     0.177949\n",
      "             ...   \n",
      "Leisure    0.362944\n",
      "Up         0.377851\n",
      "Body       0.425210\n",
      "Negate     0.442613\n",
      "Tentat     0.502498\n",
      "Certain    0.504781\n",
      "Insight    0.596597\n",
      "Negemo     0.656299\n",
      "Space      0.744772\n",
      "Physcal    0.767056\n",
      "Posemo     0.838418\n",
      "Senses     0.866276\n",
      "Discrep    0.907894\n",
      "Motion     0.930377\n",
      "Past       0.983815\n",
      "You        1.291172\n",
      "Excl       1.423621\n",
      "Affect     1.514999\n",
      "Article    1.765142\n",
      "Cogmech    1.901044\n",
      "Othref     1.939883\n",
      "Time       1.999472\n",
      "Incl       2.146318\n",
      "I          2.342971\n",
      "Self       2.468815\n",
      "Preps      2.950245\n",
      "Social     3.002472\n",
      "Pronoun    4.744396\n",
      "Present    5.203472\n",
      "Other      8.353476\n",
      "Name: Total, Length: 68, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print((df.loc['Total'].sort_values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Achieve</th>\n",
       "      <th>Affect</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Anx</th>\n",
       "      <th>Article</th>\n",
       "      <th>Assent</th>\n",
       "      <th>Body</th>\n",
       "      <th>Cause</th>\n",
       "      <th>Certain</th>\n",
       "      <th>Cogmech</th>\n",
       "      <th>...</th>\n",
       "      <th>Social</th>\n",
       "      <th>Space</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Swear</th>\n",
       "      <th>TV</th>\n",
       "      <th>Tentat</th>\n",
       "      <th>Time</th>\n",
       "      <th>Up</th>\n",
       "      <th>We</th>\n",
       "      <th>You</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.031536</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.026604</td>\n",
       "      <td>0.006164</td>\n",
       "      <td>0.005840</td>\n",
       "      <td>0.004088</td>\n",
       "      <td>0.013432</td>\n",
       "      <td>0.056778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101616</td>\n",
       "      <td>0.012978</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.006684</td>\n",
       "      <td>0.033288</td>\n",
       "      <td>0.009344</td>\n",
       "      <td>0.002660</td>\n",
       "      <td>0.052755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014433</td>\n",
       "      <td>0.003093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.030928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041237</td>\n",
       "      <td>0.011340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>0.036082</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>0.025773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001547</td>\n",
       "      <td>0.021454</td>\n",
       "      <td>0.004023</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.024291</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.010572</td>\n",
       "      <td>0.003816</td>\n",
       "      <td>0.004590</td>\n",
       "      <td>0.052347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075245</td>\n",
       "      <td>0.007530</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.003816</td>\n",
       "      <td>0.029654</td>\n",
       "      <td>0.008097</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.040175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001490</td>\n",
       "      <td>0.025034</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.022798</td>\n",
       "      <td>0.004768</td>\n",
       "      <td>0.008195</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.008195</td>\n",
       "      <td>0.035911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075399</td>\n",
       "      <td>0.012070</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.010431</td>\n",
       "      <td>0.044554</td>\n",
       "      <td>0.004917</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.027418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.031478</td>\n",
       "      <td>0.002959</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>0.058364</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.006785</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.009897</td>\n",
       "      <td>0.068007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069741</td>\n",
       "      <td>0.016581</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.019336</td>\n",
       "      <td>0.045049</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.036886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Achieve    Affect     Anger       Anx   Article    Assent      Body  \\\n",
       "0  0.000584  0.031536  0.002920  0.000908  0.026604  0.006164  0.005840   \n",
       "1  0.000000  0.014433  0.003093  0.000000  0.038144  0.000000  0.005155   \n",
       "2  0.001547  0.021454  0.004023  0.001908  0.024291  0.002630  0.010572   \n",
       "3  0.001490  0.025034  0.000894  0.000596  0.022798  0.004768  0.008195   \n",
       "4  0.000612  0.031478  0.002959  0.001377  0.058364  0.002551  0.006785   \n",
       "\n",
       "      Cause   Certain   Cogmech    ...       Social     Space    Sports  \\\n",
       "0  0.004088  0.013432  0.056778    ...     0.101616  0.012978  0.000389   \n",
       "1  0.008247  0.001031  0.030928    ...     0.041237  0.011340  0.000000   \n",
       "2  0.003816  0.004590  0.052347    ...     0.075245  0.007530  0.001650   \n",
       "3  0.001192  0.008195  0.035911    ...     0.075399  0.012070  0.000596   \n",
       "4  0.008214  0.009897  0.068007    ...     0.069741  0.016581  0.000765   \n",
       "\n",
       "      Swear        TV    Tentat      Time        Up        We       You  \n",
       "0  0.001687  0.000260  0.006684  0.033288  0.009344  0.002660  0.052755  \n",
       "1  0.001031  0.000000  0.002062  0.036082  0.004124  0.002062  0.025773  \n",
       "2  0.000722  0.000155  0.003816  0.029654  0.008097  0.002476  0.040175  \n",
       "3  0.000000  0.000149  0.010431  0.044554  0.004917  0.002235  0.027418  \n",
       "4  0.001071  0.000153  0.019336  0.045049  0.010714  0.000459  0.036886  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.read_csv('songlyrics/scripts/decade3_liwc.csv', sep='\\t', index_col=0)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc['Total']= df3.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV         0.004875\n",
      "Fillers    0.006405\n",
      "Nonfl      0.010015\n",
      "Groom      0.011801\n",
      "Death      0.013517\n",
      "Inhib      0.021108\n",
      "Down       0.021496\n",
      "School     0.024558\n",
      "Job        0.026784\n",
      "Sports     0.028976\n",
      "Achieve    0.032880\n",
      "Anx        0.034871\n",
      "Relig      0.038880\n",
      "Swear      0.039141\n",
      "Home       0.045516\n",
      "Friends    0.051548\n",
      "Metaph     0.052306\n",
      "Sexual     0.058973\n",
      "Music      0.060422\n",
      "We         0.060703\n",
      "Money      0.062509\n",
      "Optim      0.063558\n",
      "Sleep      0.067687\n",
      "Eating     0.079396\n",
      "Occup      0.084941\n",
      "Assent     0.089424\n",
      "Anger      0.093270\n",
      "Number     0.099132\n",
      "Feel       0.115572\n",
      "Family     0.117340\n",
      "             ...   \n",
      "Future     0.238001\n",
      "Hear       0.238942\n",
      "Up         0.246167\n",
      "Body       0.262449\n",
      "Tentat     0.264099\n",
      "Certain    0.270369\n",
      "Comm       0.270879\n",
      "Posemo     0.405964\n",
      "Negemo     0.424767\n",
      "Space      0.436754\n",
      "Insight    0.437796\n",
      "Physcal    0.440804\n",
      "Past       0.506967\n",
      "Senses     0.585264\n",
      "Discrep    0.634611\n",
      "Motion     0.684641\n",
      "Affect     0.838845\n",
      "Excl       0.999689\n",
      "Article    1.002130\n",
      "You        1.063881\n",
      "Time       1.181450\n",
      "Cogmech    1.343766\n",
      "Othref     1.410461\n",
      "Incl       1.536455\n",
      "I          1.877127\n",
      "Self       1.943453\n",
      "Preps      2.045603\n",
      "Social     2.187800\n",
      "Pronoun    3.552797\n",
      "Present    3.848078\n",
      "Name: Total, Length: 68, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print((df3.loc['Total'].sort_values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
